{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df418908",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForSequenceClassification, BertTokenizerFast\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# ---- CachedGELU Implementation ----\n",
    "class CachedGELU(nn.Module):\n",
    "    def __init__(self, x_min=-100.0, x_max=100.0, N=50000):\n",
    "        super().__init__()\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.N = N\n",
    "        self.step = (x_max - x_min) / (N - 1)\n",
    "        self.inv_step = 1.0 / self.step\n",
    "        x_table = torch.linspace(x_min, x_max, N)\n",
    "        y_table = 0.5 * x_table * (1.0 + torch.erf(x_table / torch.sqrt(torch.tensor(2.0))))\n",
    "        slope = torch.diff(y_table, append=y_table[-1].unsqueeze(0))\n",
    "        self.register_buffer(\"y_table\", y_table)\n",
    "        self.register_buffer(\"slope\", slope)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_clamped = torch.clamp(x, self.x_min, self.x_max)\n",
    "        idx_f = (x_clamped - self.x_min) * self.inv_step\n",
    "        idx = idx_f.long().clamp(0, self.N - 1)\n",
    "        frac = idx_f - idx.float()\n",
    "        y_val = self.y_table[idx]\n",
    "        m_val = self.slope[idx]\n",
    "        approx = y_val + frac * m_val\n",
    "        gelu_exact = 0.5 * x * (1.0 + torch.erf(x / torch.sqrt(torch.tensor(2.0, device=x.device))))\n",
    "        return torch.where((x < self.x_min) | (x > self.x_max), gelu_exact, approx)\n",
    "\n",
    "# ---- Tanh-Based GELU Approximation ----\n",
    "class GELUTanhApprox(nn.Module):\n",
    "    def forward(self, x):\n",
    "        coeff = torch.sqrt(torch.tensor(2.0 / torch.pi, device=x.device))\n",
    "        return 0.5 * x * (1.0 + torch.tanh(coeff * (x + 0.044715 * x.pow(3))))\n",
    "\n",
    "# ---- Sigmoid-Based GELU Approximation ----\n",
    "class GELUSigmoidApprox(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "# ---- Replace GELU ----\n",
    "def replace_gelu(model, mode=\"standard\"):\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.GELU):\n",
    "            if mode == \"cached\":\n",
    "                new_act = CachedGELU()\n",
    "            elif mode == \"tanh\":\n",
    "                new_act = GELUTanhApprox()\n",
    "            elif mode == \"sigmoid\":\n",
    "                new_act = GELUSigmoidApprox()\n",
    "            else:\n",
    "                new_act = nn.GELU()\n",
    "            parent = model\n",
    "            *path, last = name.split(\".\")\n",
    "            for p in path:\n",
    "                parent = getattr(parent, p)\n",
    "            setattr(parent, last, new_act)\n",
    "    return model\n",
    "\n",
    "# ---- Load BERT Model ----\n",
    "def load_bert(mode=\"standard\", compile_model=False):\n",
    "    model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-SST-2\")\n",
    "    model.eval()\n",
    "    model = replace_gelu(model, mode=mode)\n",
    "    if compile_model:\n",
    "        model = torch.compile(model)\n",
    "    return model\n",
    "\n",
    "# ---- Inference Benchmark ----\n",
    "@torch.no_grad()\n",
    "def benchmark(model, tokenizer, dataset, device, max_len=128, runs=1000000):\n",
    "    runs = min(len(dataset), runs)\n",
    "    model.to(device)\n",
    "    correct = 0\n",
    "    total_time = 0\n",
    "    for i in tqdm(range(runs), desc=\"Inference\"):\n",
    "        text = dataset[i]['sentence'] if 'sentence' in dataset[i] else dataset[i]['text']\n",
    "        label = dataset[i]['label']\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        start = time.time()\n",
    "        outputs = model(**inputs)\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        total_time += time.time() - start\n",
    "\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "        correct += int(pred == label)\n",
    "\n",
    "    avg_time = total_time / runs\n",
    "    accuracy = correct / runs * 100\n",
    "    return avg_time, accuracy\n",
    "\n",
    "# ---- Main ----\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "    dataset = load_dataset(\"glue\", \"sst2\", split=\"validation\")\n",
    "\n",
    "    configs = [\n",
    "        (\"Standard GELU\", \"standard\", False),\n",
    "        (\"Cached GELU\", \"cached\", True),\n",
    "        (\"Tanh Approx GELU\", \"tanh\", True),\n",
    "        (\"Sigmoid Approx GELU\", \"sigmoid\", True),\n",
    "    ]\n",
    "\n",
    "    for label, mode, compile_flag in configs:\n",
    "        print(f\"\\nRunning: {label}\")\n",
    "        model = load_bert(mode=mode, compile_model=compile_flag)\n",
    "        avg_time, acc = benchmark(model, tokenizer, dataset, device)\n",
    "        print(f\"{label} => Avg Inference Time: {avg_time:.6f} sec, Accuracy: {acc:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
