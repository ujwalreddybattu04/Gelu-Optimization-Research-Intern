{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3510a441",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# GELU Approximations\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class GELUManual(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1.0 + torch.erf(x / torch.sqrt(torch.tensor(2.0, device=x.device))))\n",
    "\n",
    "class GELUTanhApprox(nn.Module):\n",
    "    def forward(self, x):\n",
    "        coeff = torch.sqrt(torch.tensor(2.0 / torch.pi, device=x.device))\n",
    "        return 0.5 * x * (1.0 + torch.tanh(coeff * (x + 0.044715 * torch.pow(x, 3))))\n",
    "\n",
    "class GELUSigmoidApprox(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "class CachedGELU(nn.Module):\n",
    "    def __init__(self, x_min=-100.0, x_max=100.0, N=20000):\n",
    "        super().__init__()\n",
    "        self.x_min = x_min\n",
    "        self.x_max = x_max\n",
    "        self.N = N\n",
    "        self.step = (x_max - x_min) / (N - 1)\n",
    "        self.inv_step = 1.0 / self.step\n",
    "        x_table = torch.linspace(x_min, x_max, N)\n",
    "        y_table = 0.5 * x_table * (1.0 + torch.erf(x_table / torch.sqrt(torch.tensor(2.0))))\n",
    "        slope = torch.diff(y_table, append=y_table[-1].unsqueeze(0))\n",
    "        self.register_buffer('y_table', y_table)\n",
    "        self.register_buffer('slope', slope)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_clamped = torch.clamp(x, self.x_min, self.x_max)\n",
    "        idx_f = (x_clamped - self.x_min) * self.inv_step\n",
    "        idx = idx_f.long().clamp(0, self.N - 1)\n",
    "        frac = idx_f - idx.float()\n",
    "        y_val = self.y_table[idx]\n",
    "        m_val = self.slope[idx]\n",
    "        approx = y_val + frac * m_val\n",
    "        gelu_exact = 0.5 * x * (1.0 + torch.erf(x / torch.sqrt(torch.tensor(2.0, device=x.device))))\n",
    "        return torch.where((x < self.x_min) | (x > self.x_max), gelu_exact, approx)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Residual Block & ResNet\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, activation, stride=1):\n",
    "        super().__init__()\n",
    "        self.activation = activation\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            activation,\n",
    "            nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.shortcut(x)\n",
    "        return self.activation(out)\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, activation):\n",
    "        super().__init__()\n",
    "        self.inchannel = 64\n",
    "        self.activation = activation\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            activation\n",
    "        )\n",
    "        self.layer1 = self._make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(512, 2, stride=2)\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "    def _make_layer(self, outchannel, blocks, stride):\n",
    "        layers = [ResidualBlock(self.inchannel, outchannel, self.activation, stride)]\n",
    "        self.inchannel = outchannel\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(self.inchannel, outchannel, self.activation))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = F.avg_pool2d(x, 4)\n",
    "        return self.fc(x.view(x.size(0), -1))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Training and Evaluation\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def train_model(model, name, trainloader, testloader, device, epochs=30):\n",
    "    model = torch.compile(model)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"\\nðŸš€ Training with {name}...\\n\")\n",
    "    start = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total, correct, loss_sum = 0, 0, 0\n",
    "        for inputs, labels in trainloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "        print(f\"Epoch {epoch+1:2d} | Loss: {loss_sum:.3f} | Train Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    print(\"âœ… Evaluating...\")\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "    end = time.time()\n",
    "\n",
    "    acc = 100 * np.mean(np.array(y_pred) == np.array(y_true))\n",
    "    print(f\"\\nâœ… {name} Test Accuracy: {acc:.2f}% | Time: {end - start:.2f}s\")\n",
    "    print(\"\\nðŸ“Š Classification Report:\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=trainloader.dataset.classes))\n",
    "    print(\"ðŸ§© Confusion Matrix:\\n\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', xticklabels=trainloader.dataset.classes,\n",
    "                yticklabels=trainloader.dataset.classes, cmap=\"Blues\")\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Load CIFAR-10\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Run All Variants\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_model(ResNet(GELUManual()), \"GELU\", trainloader, testloader, device)\n",
    "train_model(ResNet(CachedGELU()), \"Cached GELU\", trainloader, testloader, device)\n",
    "train_model(ResNet(GELUTanhApprox()), \"Tanh Approx GELU \", trainloader, testloader, device)\n",
    "train_model(ResNet(GELUSigmoidApprox()), \"Sigmoid Approx GELU \", trainloader, testloader, device)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
