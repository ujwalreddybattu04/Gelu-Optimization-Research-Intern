To make Cached GELU faster without losing accuracy, we can use unevenly spaced lookup points, placing more points in the dense region where the GELU curve changes rapidly and fewer points in the flat tails. First, choose the full input range (e.g., -10 to 10) and define a dense central region around zero (e.g., -3 to 3). Allocate most of the lookup table entries (about 60–70%) inside this dense range, and the rest split equally across the two sparse tail regions. Generate three segments of x-values—left tail, dense middle, right tail—and merge them in sorted order. Precompute the corresponding GELU outputs for each x and store them along with the slope between consecutive points. During the forward pass, for any input x, use torch.bucketize (binary search) to quickly find the correct segment index, then interpolate between the two closest stored points. If x falls outside the predefined range, compute the exact GELU. This way, the lookup table resolution is concentrated where it matters most, reducing storage and computation while keeping accuracy close to the original GELU.